{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to Azure ML workspace and get deployed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "model = workspace.models['cifar-classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define score file and environment (inference configuration)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat deploy/score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat deploy/env.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(source_directory='deploy',\n",
    "                                   runtime='python',\n",
    "                                   entry_script='score.py',\n",
    "                                   conda_file='env.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy as local web service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "from azureml.core import Model\n",
    "\n",
    "local_service_name = 'local-cifar-classifier'\n",
    "local_config = LocalWebservice.deploy_configuration(port=3000)\n",
    "\n",
    "try:\n",
    "    local_service = Webservice(workspace, name=local_service_name)\n",
    "    if local_service:\n",
    "        local_service.delete()\n",
    "except WebserviceException as e:\n",
    "    print()\n",
    "\n",
    "local_service = Model.deploy(workspace, local_service_name, [model], inference_config, local_config)\n",
    "local_service.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test local service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import urllib.request\n",
    "import base64\n",
    "import io\n",
    "import requests \n",
    "import json\n",
    "import argparse\n",
    "from PIL import Image\n",
    "\n",
    "def imgToBase64(img):\n",
    "    '''Convert pillow image to base64-encoded image'''\n",
    "    imgio = BytesIO()\n",
    "    img.save(imgio, 'JPEG')\n",
    "    img_str = base64.b64encode(imgio.getvalue())\n",
    "    return img_str.decode('utf-8')\n",
    "\n",
    "def test_service(image_url, scoring_url):\n",
    "    # Download image and convert to base 64\n",
    "    with urllib.request.urlopen(image_url) as url:\n",
    "        test_img = io.BytesIO(url.read())\n",
    "\n",
    "    base64Img = imgToBase64(Image.open(test_img))\n",
    "    \n",
    "    # Get prediciton through endpoint\n",
    "    input_data = '{\\\"data\\\": \\\"'+ base64Img +'\\\"}'\n",
    "    headers = {'Content-Type':'application/json'}\n",
    "    response = requests.post(scoring_url, input_data, headers=headers)\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url = local_service.scoring_uri\n",
    "image_url = 'https://content.presspage.com/uploads/2431/1920_cairoa380new-135207.jpg?10000'\n",
    "\n",
    "prediction = test_service(image_url, scoring_url)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy as AKS service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.compute import AksCompute\n",
    "\n",
    "aks_compute_target = AksCompute(workspace, 'aks-cluster')\n",
    "\n",
    "aks_service_name = 'aks-cifar-classifier'\n",
    "aks_config = AksWebservice.deploy_configuration(cpu_cores=2, memory_gb=4, auth_enabled=False)\n",
    "\n",
    "try:\n",
    "    aks_service = Webservice(workspace, name=aks_service_name)\n",
    "    if aks_service:\n",
    "        aks_service.delete()\n",
    "except WebserviceException as e:\n",
    "    print()\n",
    "\n",
    "aks_service = Model.deploy(workspace, aks_service_name, [model], inference_config, aks_config, aks_compute_target)\n",
    "aks_service.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test AKS service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url = aks_service.scoring_uri\n",
    "image_url = 'https://content.presspage.com/uploads/2431/1920_cairoa380new-135207.jpg?10000'\n",
    "\n",
    "prediction = test_service(image_url, scoring_url)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
